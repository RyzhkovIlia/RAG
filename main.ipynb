{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем необходимые методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from pypdf import PdfReader\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import google.generativeai as genai\n",
    "from langchain_milvus.retrievers import MilvusCollectionHybridSearchRetriever\n",
    "from langchain_milvus.utils.sparse import BM25SparseEmbedding\n",
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    WeightedRanker,\n",
    "    connections,\n",
    "    utility\n",
    ")\n",
    "\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CONNECTION_URI = \"http://localhost:19530\"\n",
    "connections.connect(uri=CONNECTION_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_20194/3874339961.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  split_text = re.split('\\. ', text)\n"
     ]
    }
   ],
   "source": [
    "def load_pdf_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads text from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The extracted text from the PDF, with line breaks replaced by spaces.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "def split_text_to_token(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a given text into smaller chunks based on sentences and token limits.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The full text to be split.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of text chunks, each within the token limit.\n",
    "    \"\"\"\n",
    "    split_text = re.split('\\. ', text)\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "    token_split_texts = []\n",
    "    for text in [i for i in split_text if i != \"\"]:\n",
    "        token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "    return token_split_texts\n",
    "\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        return self.model.encode(documents)\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.model.encode([query])[0]\n",
    "    \n",
    "def get_hybrid_function(\n",
    "        text_field: str, \n",
    "        config_path: str,\n",
    "        k: int=5, \n",
    "        metric: str='IP'\n",
    "    ) -> MilvusCollectionHybridSearchRetriever:\n",
    "\n",
    "    with open(config_path, \"rb\") as f:\n",
    "        config = pickle.load(f)\n",
    "        \n",
    "    sparse_search_params = {\"metric_type\": metric}\n",
    "    dense_search_params = {\"metric_type\": metric, \"params\": {}}\n",
    "    collection = Collection(config['colection_name'])\n",
    "    collection.load()\n",
    "    retriever = MilvusCollectionHybridSearchRetriever(\n",
    "        collection = collection,\n",
    "        rerank=WeightedRanker(0.5, 0.5),\n",
    "        anns_fields=[config['dense_field'], config['sparse_field']],\n",
    "        field_embeddings=[config['dense_embedding_func'], config['sparse_embedding_func']],\n",
    "        field_search_params=[dense_search_params, sparse_search_params],\n",
    "        top_k=k,\n",
    "        text_field=text_field,\n",
    "        nprobe=20\n",
    "    )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "\n",
    "def save_params_for_retriever(\n",
    "    collection: Collection, \n",
    "    dense_field: str,\n",
    "    sparse_field: str,\n",
    "    dense_embedding_func: SentenceTransformerEmbeddings,\n",
    "    sparse_embedding_func: BM25SparseEmbedding\n",
    "    ) -> None:\n",
    "    config = {\n",
    "        'colection_name': collection.name,\n",
    "        'dense_field': dense_field,\n",
    "        'sparse_field': sparse_field,\n",
    "        'dense_embedding_func': dense_embedding_func,\n",
    "        'sparse_embedding_func': sparse_embedding_func\n",
    "    }\n",
    "\n",
    "    with open(\"config_params.pkl\", \"wb\") as f:\n",
    "        pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MILVUS Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция Pushkin удалена.\n",
      "Все коллекции удалены.\n"
     ]
    }
   ],
   "source": [
    "# Удаляем предыдущие коллекции\n",
    "\n",
    "collections = utility.list_collections()\n",
    "\n",
    "# Удаляем каждую коллекцию из списка\n",
    "for collection_name in collections:\n",
    "    collection = Collection(name=collection_name)\n",
    "    collection.drop()\n",
    "    print(f\"Коллекция {collection_name} удалена.\")\n",
    "\n",
    "print(\"Все коллекции удалены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_field = \"doc_id\"\n",
    "dense_field = \"dense_vector\"\n",
    "sparse_field = \"sparse_vector\"\n",
    "text_field = \"text\"\n",
    "fields = [\n",
    "    FieldSchema(\n",
    "        name=pk_field,\n",
    "        dtype=DataType.VARCHAR,\n",
    "        is_primary=True,\n",
    "        auto_id=True,\n",
    "        max_length=100,\n",
    "    ),\n",
    "    FieldSchema(name=dense_field, dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "    FieldSchema(name=sparse_field, dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=text_field, dtype=DataType.VARCHAR, max_length=65_535),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = CollectionSchema(fields=fields, enable_dynamic_field=False)\n",
    "collection = Collection(\n",
    "    name=\"Moscow\", schema=schema, consistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(\"dense_vector\", dense_index)\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(\"sparse_vector\", sparse_index)\n",
    "collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = load_pdf_file(file_path='dataset/skazka_o_rubake_i_rubke.pdf')\n",
    "chunked_text = split_text_to_token(text=pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embedding_func = SentenceTransformerEmbeddings()\n",
    "sparse_embedding_func = BM25SparseEmbedding(corpus=chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "for text in chunked_text:\n",
    "    entity = {\n",
    "        dense_field: dense_embedding_func.embed_documents([text])[0],\n",
    "        sparse_field: sparse_embedding_func.embed_documents([text])[0],\n",
    "        text_field: text,\n",
    "    }\n",
    "    entities.append(entity)\n",
    "collection.insert(entities)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params_for_retriever(\n",
    "    collection=collection, \n",
    "    dense_field=dense_field, \n",
    "    sparse_field=sparse_field,\n",
    "    dense_embedding_func=dense_embedding_func,\n",
    "    sparse_embedding_func=sparse_embedding_func\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Используем MILVUS для поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_collection = 'Pushkin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = get_hybrid_function(\n",
    "    text_field='text', \n",
    "    config_name=f'config_params_{name_of_collection}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query:str, relevant_passage:str) -> str:\n",
    "    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    prompt = f\"\"\"\n",
    "    Human: You are a helpful and informative bot that answers questions using text from the passage below. \n",
    "    Be sure to answer in a full sentence, exhaustively, including all relevant background information.\n",
    "    However, you are speaking to a non-technical audience, so be sure to break down complex concepts and\n",
    "    keep your tone friendly and accommodating.\n",
    "    If the passage is not relevant to the answer, you can ignore it.\n",
    "    Context is given between <context>.\n",
    "    The question is given between </question>.\n",
    "    Thank you!\n",
    "\n",
    "    <context>\n",
    "    {escaped}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {query}\n",
    "    </question>\n",
    "\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_model() -> genai.GenerativeModel:\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_promt(query:str, model: genai.GenerativeModel, collection:MilvusCollectionHybridSearchRetriever) -> str:\n",
    "    similar_docs = collection.invoke(query)\n",
    "    relevant_text = \". \".join([doc.page_content.capitalize() for doc in similar_docs])\n",
    "\n",
    "    prompt = make_rag_prompt(query=query, relevant_passage=relevant_text)\n",
    "\n",
    "    answer = model.generate_content(prompt)\n",
    "    \n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pain signals are made up of two components: first pain and second pain. First pain is rapidly transmitted and has high spatial resolution, meaning it can be precisely localized. Second pain is much slower, poorly localized, and poorly tolerated.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_gpt_model()\n",
    "query=\"What are the components of pain signals?\"\n",
    "answer = generate_answer_promt(query=query, model=model, collection=retriever)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = db.get(include=['embeddings'])['embeddings']\n",
    "# umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def project_embeddings(embeddings, umap_transform):\n",
    "#     umap_embeddings = np.empty((len(embeddings),2))\n",
    "#     for i, embedding in enumerate(tqdm(embeddings)): \n",
    "#         umap_embeddings[i] = umap_transform.transform([embedding])\n",
    "#     return umap_embeddings   \n",
    "\n",
    "# projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_embedding = embedding_function([query])[0]\n",
    "# retrieved_embeddings = relevant_text['embeddings'][0]\n",
    "\n",
    "# projected_query_embedding = project_embeddings([query_embedding], umap_transform)\n",
    "# projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "# plt.scatter(projected_query_embedding[:, 0], projected_query_embedding[:, 1], s=50, marker='X', color='r')\n",
    "# plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "\n",
    "# plt.gca().set_aspect('equal', 'datalim')\n",
    "# plt.title(f'{query}')\n",
    "# plt.show()\n",
    "# # plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_query_embedding = embedding_function([joint_query])\n",
    "# original_query_embedding = embedding_function([query])\n",
    "# retrieved_embeddings = relevant_text['embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projected_original_query_embedding = project_embeddings(original_query_embedding, umap_transform)\n",
    "# projected_augmented_query_embedding = project_embeddings(augmented_query_embedding, umap_transform)\n",
    "# projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "# plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "# plt.scatter(projected_original_query_embedding[:, 0], projected_original_query_embedding[:, 1], s=50, marker='X', color='r')\n",
    "# plt.scatter(projected_augmented_query_embedding[:, 0], projected_augmented_query_embedding[:, 1], s=50, marker='X', color='blue')\n",
    "\n",
    "# plt.gca().set_aspect('equal', 'datalim')\n",
    "# plt.title(f'{query}')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
